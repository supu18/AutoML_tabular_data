{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "VHmItv6_hcg-",
      "metadata": {
        "id": "VHmItv6_hcg-"
      },
      "source": [
        "# **ALL TOOLS ON DECK**\n",
        "\n",
        "---\n",
        "AutoGluon is a cutting-edge tool for automating machine learning (AutoML) processes on tabular datasets. The objective is to investigate the performance of several AutoML tools, including Auto-sklearn, FLAML,TPOT and MLJAR in comparison to AutoGluon's predictive capabilities.\n",
        "\n",
        "While AutoGluon typically excels in longer training durations, our focus lies in examining its performance within shorter training times, specifically less than a minute. We aim to contrast this with an AutoGluon predictor trained for an equivalent total duration.\n",
        "\n",
        "# Overview of AutoML Tools\n",
        "## 1. AutoGluon\n",
        "Description: AutoGluon is an open-source AutoML framework from Amazon that focuses on ease of use and high performance. It automates machine learning workflows, including feature engineering, model selection, and hyperparameter tuning.\n",
        "### Strengths:\n",
        "*   Versatility: Supports multiple data types and tasks (e.g., regression, classification).\n",
        "*   Ensemble Learning: Automatically builds ensembles of models.\n",
        "*   Efficiency: Optimized for performance with multi-threading and GPU support.\n",
        "\n",
        "## 2. MLJAR\n",
        "Description: MLJAR is a Python library that automates the machine learning pipeline with a focus on simplicity and interpretability. It also supports multiple types of data and tasks.\n",
        "### Strengths:\n",
        "*   Easy-to-Use Interface: Simplified API for quick model training.\n",
        "*   Ensemble Learning: Combines multiple models to improve performance.\n",
        "*   Feature Importance: Provides insights into feature importance.\n",
        "\n",
        "## 3. TPOT\n",
        "Description: TPOT (Tree-based Pipeline Optimization Tool) is an AutoML tool that uses genetic algorithms to optimize machine learning pipelines. It's part of the scikit-learn ecosystem.\n",
        "### Strengths:\n",
        "\n",
        "\n",
        "*   Pipeline Optimization: Automatically designs and optimizes machine learning pipelines.\n",
        "*   Genetic Algorithms: Uses evolutionary algorithms to find the best models.\n",
        "* Customization: Allows for detailed control over the optimization process.\n",
        "\n",
        "Sure! Here is the information for Auto-sklearn and FLAML in the same format:\n",
        "\n",
        "## 4. Auto-sklearn\n",
        "Description: Auto-sklearn is an open-source AutoML tool built on top of the scikit-learn library. It uses Bayesian optimization to automate the process of model selection and hyperparameter tuning.\n",
        "### Strengths:\n",
        "*   Bayesian Optimization: Efficiently searches the hyperparameter space.\n",
        "*   Meta-Learning: Leverages prior knowledge to warm-start the optimization.\n",
        "*   Ensemble Learning: Automatically constructs ensembles of models to improve performance.\n",
        "*   Extensible: Integrates well with the scikit-learn ecosystem, allowing for custom pipelines and preprocessing.\n",
        "\n",
        "## 5. FLAML\n",
        "Description: FLAML (Fast and Lightweight AutoML) is a lightweight open-source library developed by Microsoft Research. It focuses on efficient and fast AutoML for both classification and regression tasks.\n",
        "### Strengths:\n",
        "*   Efficiency: Optimized for fast performance and low computational cost.\n",
        "*   Simplicity: Easy-to-use interface with minimal setup.\n",
        "*   Customization: Allows users to specify constraints and customize the search space.\n",
        "*   Versatility: Supports a range of machine learning tasks including time series forecasting.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9r-JNiJkhRy_",
      "metadata": {
        "id": "9r-JNiJkhRy_"
      },
      "source": [
        "Install All Required package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b701ff-d3ee-45a6-ac60-73a334825a24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a4b701ff-d3ee-45a6-ac60-73a334825a24",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e3d04ec3-59d8-4f22-d0fb-29d4d5d00702",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install flaml\n",
        "!pip install tpot\n",
        "!pip install mljar-supervised\n",
        "!pip install autogluon\n",
        "!pip install scikit-learn\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc729b0f-7ab3-48a7-ac0b-0e93e1dd8d75",
      "metadata": {
        "id": "fc729b0f-7ab3-48a7-ac0b-0e93e1dd8d75",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "#import autosklearn.regression ## It seems like the enviroments to run Autosklearn and FLAML are uncompatible with this setup. Save one of the predictions before installing different env\n",
        "\n",
        "#from flaml import AutoML\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import logging\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from scipy.stats import entropy\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caNIROmEh7pq",
      "metadata": {
        "id": "caNIROmEh7pq"
      },
      "source": [
        "Parameters Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jm39vqLZh7Rh",
      "metadata": {
        "id": "jm39vqLZh7Rh"
      },
      "outputs": [],
      "source": [
        "\n",
        "random_seed = 42\n",
        "time = 45"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75540722-50a6-46a9-ad65-b94ea6b468c1",
      "metadata": {
        "id": "75540722-50a6-46a9-ad65-b94ea6b468c1"
      },
      "source": [
        "# Load different datsets with respect to the dataset of the experiement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3dc723-51fc-49cf-b53e-d76b40ae3a17",
      "metadata": {
        "collapsed": true,
        "id": "bb3dc723-51fc-49cf-b53e-d76b40ae3a17",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "7ce2eb73-cdd1-48f5-d61b-6a5e842e0478",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Final dataset\n",
        "\n",
        "base_path = '../../data/exam_dataset'\n",
        "\n",
        "X_train = pd.read_parquet(f'{base_path}/X_train.parquet')\n",
        "y_train = pd.read_parquet(f'{base_path}/y_train.parquet')\n",
        "train_dataset = pd.concat([X_train, y_train], axis=1)\n",
        "#test = train_dataset.sample(frac=0.2, replace=False, random_state=random_seed)\n",
        "exam_X_values = pd.read_parquet(f'{base_path}/X_test.parquet')\n",
        "\n",
        "# Also instantiate the target column\n",
        "label = 'price'\n",
        "\n",
        "\n",
        "\n",
        "print(train_dataset.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2909254f-c9e6-408a-86cb-38dde82f4abb",
      "metadata": {
        "collapsed": true,
        "id": "2909254f-c9e6-408a-86cb-38dde82f4abb",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "outputId": "debcc868-5945-4bb8-8b3b-210e9ddfd023",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Change path respective to the dataset you are testing:\n",
        "#  * Bike_Sharing_Demand (361099) - label: 'count'\n",
        "#  * Brazilian Houses (361098) - label: 'total_(BRL)'\n",
        "#  * y_prop_4_1 (361092) - label: 'oz252'\n",
        "# Because the exam dataset is ~20,000 entries, we should sample around this as well maybe?\n",
        "\n",
        "# Set the base path for the dataset\n",
        "base_path = '../../data/361099'\n",
        "\n",
        "# Initialize variables for training data\n",
        "X_train = None\n",
        "y_train = None\n",
        "\n",
        "# Loop through each fold of the dataset\n",
        "for fold_number in range(1, 11):\n",
        "    # Read the X_train and y_train data for the current fold\n",
        "    x_fold = pd.read_parquet(f'{base_path}/{fold_number}/X_train.parquet')\n",
        "    y_fold = pd.read_parquet(f'{base_path}/{fold_number}/y_train.parquet')\n",
        "\n",
        "    # Concatenate the data to the existing training data\n",
        "    if X_train is None:\n",
        "        X_train = x_fold\n",
        "        y_train = y_fold\n",
        "    else:\n",
        "        X_train = pd.concat([X_train, x_fold])\n",
        "        y_train = pd.concat([y_train, y_fold])\n",
        "\n",
        "# Sample the training data to around 20,000 entries\n",
        "X_train = X_train.sample(n=20000, random_state=random_seed)\n",
        "y_train = y_train.sample(n=20000, random_state=random_seed)\n",
        "\n",
        "# Create a concatenated dataset for gluon\n",
        "train_dataset = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# Initialize variable for test data\n",
        "test = None\n",
        "\n",
        "# Loop through each fold of the dataset\n",
        "for fold_number in range(1, 11):\n",
        "    # Read the X_test and y_test data for the current fold\n",
        "    x_fold = pd.read_parquet(f'{base_path}/{fold_number}/X_test.parquet')\n",
        "    y_fold = pd.read_parquet(f'{base_path}/{fold_number}/y_test.parquet')\n",
        "\n",
        "    # Concatenate the data to the existing test data\n",
        "    concat_fold = pd.concat([x_fold, y_fold], axis=1)\n",
        "    if test is None:\n",
        "        test = concat_fold\n",
        "    else:\n",
        "        test = pd.concat([test, concat_fold])\n",
        "\n",
        "# Set the label for the dataset\n",
        "label = 'count'\n",
        "\n",
        "# Print the information of the training dataset\n",
        "print(train_dataset.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a414e7",
      "metadata": {},
      "source": [
        "## Run this job first, then switch from conda kernel and run the script again excluding this cell\n",
        "\n",
        "# AutoSKLearn Training\n",
        "\n",
        "Auto-sklearn automates the process of model selection and hyperparameter tuning to optimize machine learning pipelines. Save the best pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ccfe5c0-ea33-4a00-8587-aed9d93f408b",
      "metadata": {
        "id": "8ccfe5c0-ea33-4a00-8587-aed9d93f408b",
        "outputId": "4c4029eb-d0eb-4d6b-ced3-ee19d46d4b37",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] [2024-08-03 12:30:28,376:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
          ]
        }
      ],
      "source": [
        "# Import the autosklearn.regression module\n",
        "import autosklearn.regression\n",
        "\n",
        "# Fit the AutoSklearnRegressor model with the given time budget\n",
        "autosklearn = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=time, n_jobs=-1).fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the exam dataset\n",
        "autosklearn_pred = autosklearn.predict(exam_X_values)\n",
        "\n",
        "# Save the predictions to a pickle file\n",
        "with open('autosklearn_pred_exam.pkl', 'wb') as f:\n",
        "    pickle.dump(autosklearn_pred, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1fd9fa8-f5cd-4d36-855f-480eb4cd221c",
      "metadata": {
        "id": "f1fd9fa8-f5cd-4d36-855f-480eb4cd221c"
      },
      "source": [
        "## Switch kernel to python default before running this\n",
        "### Also need to run imports and variables again"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf71b6e",
      "metadata": {},
      "source": [
        "# FLAML Training\n",
        "\n",
        "Train a FLAML model which uses efficient hyperparameter optimization to optimize machine learning pipelines. The best pipeline is saved and then used for making predictions. FLAML focuses on pipeline optimization and offers a high degree of automation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6fbd939-8b2a-466c-8a18-5d8d2b29245a",
      "metadata": {
        "id": "a6fbd939-8b2a-466c-8a18-5d8d2b29245a",
        "outputId": "d71d7682-33da-46ab-def0-e02f1a33e501",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Instantiate the AutoML object\n",
        "flaml = AutoML()\n",
        "\n",
        "# Define the list of learners to be used\n",
        "learners = ['lgbm', 'rf', 'catboost', 'extra_tree', 'kneighbor']\n",
        "\n",
        "# Fit the AutoML model\n",
        "flaml.fit(\n",
        "    np.array(X_train),  # Training data features\n",
        "    np.array(y_train),  # Training data labels\n",
        "    task=\"regression\",  # Task type is regression\n",
        "    time_budget=time,  # Time budget for the AutoML search\n",
        "    estimator_list=learners,  # List of learners to be used\n",
        "    verbose=1  # Set verbosity level to 1 for progress updates\n",
        ")\n",
        "\n",
        "# Make predictions on the exam dataset\n",
        "flaml_pred = flaml.predict(exam_X_values)\n",
        "\n",
        "# Save the predictions to a pickle file\n",
        "with open(f'flaml_pred_exam.pkl', 'wb') as f:\n",
        "    pickle.dump(flaml_pred, f)\n",
        "#flaml_score = r2_score(test[label], flaml_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f790d07",
      "metadata": {},
      "source": [
        "# AutoGluon Training\n",
        "\n",
        "Train a model which uses an automated machine learning (AutoML) library Autogluon designed to simplify the process of training and optimizing machine learning models. The predictions are saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1daa198b-ce23-4b53-b99c-c75b34d96acd",
      "metadata": {
        "id": "1daa198b-ce23-4b53-b99c-c75b34d96acd",
        "outputId": "73f9080f-1b62-4b38-d896-8ed91b3a48c0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Fit the AutoGluon model with the given time budget\n",
        "gluon = TabularPredictor(label=label, problem_type='regression', eval_metric='r2').fit(train_dataset, time_limit=time, presets='medium_quality', verbosity=1)\n",
        "\n",
        "# Make predictions on the exam dataset\n",
        "gluon_pred = gluon.predict(exam_X_values)\n",
        "\n",
        "# Save the predictions to a pickle file\n",
        "with open('gluon_predictions_EXAM.pkl', 'wb') as f:\n",
        "    pickle.dump(gluon_pred, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8219ad2-2eb5-4506-aa9e-08ffcf653635",
      "metadata": {
        "id": "b8219ad2-2eb5-4506-aa9e-08ffcf653635"
      },
      "source": [
        "# TPOT Training\n",
        "Train a TPOT model which uses genetic algorithms to optimize machine learning pipelines. The best pipeline is saved and then used for making predictions. TPOT focuses on pipeline optimization and offers a high degree of automation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587594c1-78a9-4d4b-a288-c32c597eba4f",
      "metadata": {
        "id": "587594c1-78a9-4d4b-a288-c32c597eba4f",
        "jupyter": {
          "source_hidden": true
        },
        "outputId": "244a828a-c3be-4adc-b7e2-9e5e9ad6fe2c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TPOT R2 score: 0.8568653401098989\n"
          ]
        }
      ],
      "source": [
        "from tpot import TPOTRegressor\n",
        "import joblib\n",
        "\n",
        "# Import the necessary libraries\n",
        "\n",
        "# Instantiate the TPOTRegressor\n",
        "tpot = TPOTRegressor(\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1,              # Utilize all CPU cores\n",
        "    max_time_mins=1,        # Max total time in minutes\n",
        "    max_eval_time_mins=0.2  # Max time per pipeline in minutes\n",
        ")\n",
        "\n",
        "# Fit the TPOTRegressor on the training data\n",
        "tpot.fit(X_train, y_train)\n",
        "\n",
        "# Save the fitted pipeline\n",
        "joblib.dump(tpot.fitted_pipeline_, \"tpot_pipeline.joblib\")\n",
        "\n",
        "# At prediction time, load the saved pipeline\n",
        "loaded_pipeline = joblib.load(\"tpot_pipeline.joblib\")\n",
        "\n",
        "# Make predictions using the loaded pipeline\n",
        "tpot_predictions = loaded_pipeline.predict(test.drop(columns=[label]))\n",
        "\n",
        "# Calculate the R2 score of TPOT predictions\n",
        "tpot_score = r2_score(test[label], tpot_predictions)\n",
        "\n",
        "# Print the TPOT R2 score\n",
        "print(\"TPOT R2 score:\", tpot_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32595603",
      "metadata": {
        "id": "32595603"
      },
      "source": [
        "#  MLJAR Training\n",
        "Train an MLJAR model using the full dataset. MLJAR performs automated machine learning and provides a model that is evaluated on a test set. It focuses on easy-to-use interfaces and interpretability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PAzC2A1_TjeB",
      "metadata": {
        "id": "PAzC2A1_TjeB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from supervised import AutoML\n",
        "\n",
        "# Prepare data\n",
        "X_train = train_dataset.drop(columns=[label])\n",
        "y_train = train_dataset[label]\n",
        "\n",
        "# Initialize AutoML for regression\n",
        "mljar_automl_regressor = AutoML(\n",
        "    mode=\"Compete\",\n",
        "    total_time_limit=90,\n",
        "    random_state=random_seed,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit AutoML\n",
        "mljar_automl_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "mljar_predict = mljar_automl_regressor.predict(exam_X_values)\n",
        "\n",
        "# Save the model as a pickle file\n",
        "with open('mljar_model_EXAM.pkl', 'wb') as f:\n",
        "    pickle.dump(mljar_automl_regressor, f)\n",
        "\n",
        "# Save the predictions to a pickle file\n",
        "with open('mljar_predictions_EXAM.pkl', 'wb') as f:\n",
        "    pickle.dump(mljar_predict, f)\n",
        "\n",
        "# Print completion messages\n",
        "print(\"Model training completed and model saved as 'mljar_model_EXAM.pkl'.\")\n",
        "print(\"Predictions saved as 'mljar_predictions_EXAM.pkl'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50eb691c-7ab5-45b0-aac6-9f007b23f2ff",
      "metadata": {
        "id": "50eb691c-7ab5-45b0-aac6-9f007b23f2ff"
      },
      "source": [
        "# Load all predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0133d089-3a77-43f7-9b26-466d4f9d290a",
      "metadata": {
        "id": "0133d089-3a77-43f7-9b26-466d4f9d290a",
        "outputId": "f680984c-acbe-430d-a684-2cadc7463aab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13.67054082 12.99571632 12.26738305 ... 12.68263049 12.77947423\n",
            " 12.12948934] 2162\n"
          ]
        }
      ],
      "source": [
        "# Load the mljar pred\n",
        "with open('mljar_predictions_EXAM.pkl', 'rb') as f:\n",
        "    mljar_pred = pickle.load(f)\n",
        "\n",
        "#mljar_score = r2_score(test[label][0:len(mljar_pred)], mljar_pred)\n",
        "print(mljar_pred, len(mljar_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62450c1a-dbb4-47e3-858c-0af93c7d5c1e",
      "metadata": {
        "id": "62450c1a-dbb4-47e3-858c-0af93c7d5c1e",
        "outputId": "e220f312-9626-44e5-a43b-a3140b3f666a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.980278110859552\n"
          ]
        }
      ],
      "source": [
        "# Load the flaml score\n",
        "with open('flaml_pred_exam.pkl', 'rb') as f:\n",
        "    flaml_pred = pickle.load(f)\n",
        "\n",
        "#flaml_score = r2_score(test[label], flaml_pred)\n",
        "print(flaml_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb649b2-37de-4bd7-87f8-b8e742764d9d",
      "metadata": {
        "id": "abb649b2-37de-4bd7-87f8-b8e742764d9d",
        "outputId": "e4de5b66-bb33-4253-aafd-53b532113c4c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13.77257299 12.98191023 12.3235178  ... 12.63088846 12.71451759\n",
            " 12.15282154] 2162\n"
          ]
        }
      ],
      "source": [
        "# Load the AutoSKLEARN model\n",
        "with open('autosklearn_pred_exam.pkl', 'rb') as f:\n",
        "    autosklearn_pred = pickle.load(f)\n",
        "\n",
        "#autosklearn_score = r2_score(test[label], autosklearn_pred)\n",
        "print(autosklearn_pred, len(autosklearn_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d767df65",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the gluon predictions\n",
        "with open('gluon_predictions_EXAM.pkl', 'rb') as f:\n",
        "    gluon_pred = pickle.load(f)\n",
        "\n",
        "#gluon_score = r2_score(test[label], gluon_pred)\n",
        "print(gluon_pred, len(gluon_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b8f5fd",
      "metadata": {},
      "source": [
        "# Optimize a weighted ensemble prediction\n",
        "\n",
        "### TPOT is excluded due to poor performance measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ce85f9-3a0d-4121-8485-b84021d1d8ae",
      "metadata": {
        "id": "14ce85f9-3a0d-4121-8485-b84021d1d8ae",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real\n",
        "\n",
        "# Initial R2 scores\n",
        "r2_flaml = flaml_score.clip(min=0)\n",
        "r2_autosklearn = autosklearn_score.clip(min=0)\n",
        "r2_gluon = eval_gluon['r2'].clip(min=0)\n",
        "r2_mljar = mljar_score.clip(min=0)\n",
        "\n",
        "# Normalize R2 scores to use as initial weights\n",
        "total_r2 = r2_flaml + r2_autosklearn + r2_gluon + r2_mljar\n",
        "initial_weights = [r2_flaml/total_r2, r2_autosklearn/total_r2, r2_gluon/total_r2, r2_mljar/total_r2]\n",
        "\n",
        "def objective(weights):\n",
        "    \"\"\"\n",
        "    Objective function for optimization.\n",
        "    Calculates the ensemble prediction using the given weights and returns the negative R2 score.\n",
        "    \"\"\"\n",
        "    w1, w2, w3, w4 = weights\n",
        "    ensemble_pred = (w1 * flaml_pred + w2 * autosklearn_pred + w3 * gluon_pred +\n",
        "                     w4 * mljar_pred) / (w1 + w2 + w3 + w4)\n",
        "    return -r2_score(test[label], ensemble_pred)\n",
        "\n",
        "# Define the search space\n",
        "space = [Real(max(0, w-0.3), min(1, w+0.3), name=f'w{i+1}') for i, w in enumerate(initial_weights)]\n",
        "# Set up the optimization\n",
        "res = gp_minimize(objective, space, n_calls=50, random_state=random_seed, x0=initial_weights)\n",
        "\n",
        "# Start from the initial weights\n",
        "\n",
        "best_weights = res.x\n",
        "total = sum(best_weights)\n",
        "normalized_weights = [w/total for w in best_weights]\n",
        "w1, w2, w3, w4 = normalized_weights\n",
        "\n",
        "optimal_ensemble = (w1 * flaml_pred + w2 * autosklearn_pred + w3 * gluon_pred +\n",
        "                    w4 * mljar_pred) / (w1 + w2 + w3 + w4)\n",
        "optimal_r2 = r2_score(test[label], optimal_ensemble)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb35b91a",
      "metadata": {},
      "source": [
        "# Make the final ensemble-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feaa4121-4570-48ec-bb8c-edaea00b8247",
      "metadata": {
        "id": "feaa4121-4570-48ec-bb8c-edaea00b8247",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Predictions of the final exam X dataset\n",
        "\n",
        "# Ensemble to use from testing: AutoSklearn: 0.067, Gluon: 0.584, TPOT: 0.0000, MLJAR: 0.34891\n",
        "\n",
        "final_exam_pred = (0.067 * autosklearn_pred + 0.584 * gluon_pred + 0.349 * mljar_pred)\n",
        "\n",
        "# Convert to numpy array\n",
        "predictions_array = final_exam_pred.to_numpy()\n",
        "\n",
        "np.save('final_test_preds.npy', predictions_array)\n",
        "\n",
        "loaded_preds = np.load('final_test_preds.npy')\n",
        "print(loaded_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a22ebca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare it with a longer gluon run (benchmark)\n",
        "\n",
        "gluon_benchmark = TabularPredictor(label=label, problem_type='regression', eval_metric='r2').fit(train_dataset, time_limit=180, presets='medium_quality', verbosity=1)\n",
        "benchmark_pred = gluon_benchmark.predict(test.drop(columns=[label]))\n",
        "eval_benchmark = gluon_benchmark.evaluate(test)\n",
        "\n",
        "print('A 180 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e464947-341d-4450-8f5f-b8e5993d4544",
      "metadata": {
        "id": "9e464947-341d-4450-8f5f-b8e5993d4544",
        "tags": []
      },
      "source": [
        "# Print results of different experiements\n",
        "\n",
        "Compare the performance of the models trained by AutoGluon, MLJAR, FLAML , Auto-Sklearn based on the R2 score, which measures the goodness of fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb45c0d1-f768-46b3-aa5a-c45ef08e7a80",
      "metadata": {
        "id": "eb45c0d1-f768-46b3-aa5a-c45ef08e7a80",
        "outputId": "b00efe5d-1e40-4046-a31a-9af2384ee9f8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 21 - EXAM, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.9018991352967078\n",
            "flaml r2: 0.903215268789459\n",
            "gluon r2: 0.9086400096192336\n",
            "mljar r2: 0.9066244754568729\n",
            "Initial weights: FLAML: 0.249, AutoSklearn: 0.249, Gluon: 0.251, MLJAR: 0.2510\n",
            "Optimal weights: FLAML: 0.000, AutoSklearn: 0.121, Gluon: 0.656, MLJAR: 0.2225\n",
            "Optimal ensemble R2: 0.909100\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 21 - EXAM, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, MLJAR: {initial_weights[2]:.4f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, MLJAR: {w4:.4f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b5151a-2a01-4968-95ef-4e02895ec2ce",
      "metadata": {
        "id": "c7b5151a-2a01-4968-95ef-4e02895ec2ce",
        "outputId": "6637130e-e7a9-4d16-88f0-bfaa58d8e6c7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 20 - Bike, random_seed=21, 180 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.9711783604432226\n",
            "flaml r2: 0.980278110859552\n",
            "gluon r2: 0.9789584859714217\n",
            "mljar r2: 0.9807043791233425\n",
            "Initial weights: FLAML: 0.251, AutoSklearn: 0.248, Gluon: 0.250, MLJAR: 0.2503\n",
            "Optimal weights: FLAML: 0.486, AutoSklearn: 0.000, Gluon: 0.000, MLJAR: 0.5142\n",
            "Optimal ensemble R2: 0.986615\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 20 - Bike, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, MLJAR: {initial_weights[2]:.4f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, MLJAR: {w4:.4f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4be9727-b334-4ad6-a9b2-cc46d64f192c",
      "metadata": {
        "id": "a4be9727-b334-4ad6-a9b2-cc46d64f192c",
        "outputId": "a9b9892d-f990-41f8-9aa7-5520fb9a8dfb",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 19 - Brazil, random_seed=21, 180 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.9997569800698058\n",
            "flaml r2: 0.9999512347718132\n",
            "gluon r2: 0.999960956341897\n",
            "mljar r2: 0.9999051208946943\n",
            "Initial weights: FLAML: 0.250, AutoSklearn: 0.250, Gluon: 0.250, MLJAR: 0.2500\n",
            "Optimal weights: FLAML: 0.309, AutoSklearn: 0.008, Gluon: 0.428, MLJAR: 0.2547\n",
            "Optimal ensemble R2: 0.999976\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 19 - Brazil, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, MLJAR: {initial_weights[2]:.4f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, MLJAR: {w4:.4f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c8e36a4-90b2-42bc-87b0-86aa757b985f",
      "metadata": {
        "id": "8c8e36a4-90b2-42bc-87b0-86aa757b985f",
        "outputId": "4b2e6f8c-7271-40c9-d945-a2a5cd8c6c2e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 18 property, random_seed=21, 180 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.6493061332266326\n",
            "flaml r2: 0.9216527799760716\n",
            "gluon r2: 0.8899306049614928\n",
            "mljar r2: 0.9076180029394667\n",
            "Initial weights: FLAML: 0.274, AutoSklearn: 0.193, Gluon: 0.264, MLJAR: 0.2642\n",
            "Optimal weights: FLAML: 0.560, AutoSklearn: 0.000, Gluon: 0.000, MLJAR: 0.4404\n",
            "Optimal ensemble R2: 0.946380\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 18 - property, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, MLJAR: {initial_weights[2]:.4f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, MLJAR: {w4:.4f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83577ad-5a86-4835-9042-37f2618631e2",
      "metadata": {
        "id": "d83577ad-5a86-4835-9042-37f2618631e2",
        "outputId": "e1218fc3-3298-4777-b794-b5559c8abc5b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 17 (exam set), split train/test: 0.2, random_seed=22, 300 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.8969039991304489\n",
            "flaml r2: 0.8978766056739506\n",
            "gluon r2: 0.9036253357963947\n",
            "tpot r2: 0.8568653401098989\n",
            "mljar r2: 0.9008634374359363\n",
            "Initial weights: FLAML: 0.249, AutoSklearn: 0.249, Gluon: 0.251, TPOT: 0.2511, MLJAR: 0.25106\n",
            "Optimal weights: FLAML: 0.000, AutoSklearn: 0.000, Gluon: 0.615, TPOT: 0.0000, MLJAR: 0.38536\n",
            "Optimal ensemble R2: 0.903428\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 17 (exam set), split train/test: 0.2, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99358f65-bd65-484b-813d-44f537715542",
      "metadata": {
        "id": "99358f65-bd65-484b-813d-44f537715542",
        "outputId": "e40666dd-d8b3-47cd-c0b9-c1301e207b0e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 16 (exam set), split train/test: 0.2, random_seed=21, 180 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.8989279448427613\n",
            "flaml r2: 0.8960400316232903\n",
            "gluon r2: 0.9008207868994915\n",
            "tpot r2: 0.8568653401098989\n",
            "mljar r2: 0.8999698409260453\n",
            "Initial weights: FLAML: 0.201, AutoSklearn: 0.202, Gluon: 0.202, TPOT: 0.2023, MLJAR: 0.20231\n",
            "Optimal weights: FLAML: 0.000, AutoSklearn: 0.261, Gluon: 0.460, TPOT: 0.0000, MLJAR: 0.27934\n",
            "Optimal ensemble R2: 0.902039\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 16 (exam set), split train/test: 0.2, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e923e08-d128-4ead-b226-24b3961f16a0",
      "metadata": {
        "id": "4e923e08-d128-4ead-b226-24b3961f16a0",
        "outputId": "849a42e0-ccf3-4a5c-94ee-fb757ff570aa",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 15 (exam set), split train/test: 0.2, random_seed=20, 90 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.8999241727897213\n",
            "flaml r2: 0.9015054467686099\n",
            "gluon r2: 0.9052667552869527\n",
            "tpot r2: 0.8596347668809607\n",
            "mljar r2: 0.9035029820680053\n",
            "Initial weights: FLAML: 0.202, AutoSklearn: 0.201, Gluon: 0.203, TPOT: 0.2025, MLJAR: 0.20253\n",
            "Optimal weights: FLAML: 0.072, AutoSklearn: 0.000, Gluon: 0.670, TPOT: 0.0000, MLJAR: 0.25814\n",
            "Optimal ensemble R2: 0.905631\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 15 (exam set), split train/test: 0.2, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57e49e96-948d-4917-94de-0c344212f6b6",
      "metadata": {
        "id": "57e49e96-948d-4917-94de-0c344212f6b6",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data for optimal ensemble weights\n",
        "experiments = ['Bike', 'Brazil', 'Property', 'Exam']\n",
        "weights = [\n",
        "    {'FLAML': 0.495, 'AutoSklearn': 0.000, 'Gluon': 0.238, 'TPOT': 0.0000, 'MLJAR': 0.26731},\n",
        "    {'FLAML': 0.273, 'AutoSklearn': 0.000, 'Gluon': 0.544, 'TPOT': 0.0000, 'MLJAR': 0.18274},\n",
        "    {'FLAML': 0.790, 'AutoSklearn': 0.000, 'Gluon': 0.066, 'TPOT': 0.0000, 'MLJAR': 0.14347},\n",
        "    {'FLAML': 0.000, 'AutoSklearn': 0.067, 'Gluon': 0.584, 'TPOT': 0.0000, 'MLJAR': 0.34891}\n",
        "]\n",
        "\n",
        "# R2 scores\n",
        "ensemble_r2 = [0.983029, 0.999959, 0.929676, 0.908760]\n",
        "autogluon_r2 = [0.980324167040719, 0.9999610596082303, 0.8973623343877719, 0.9090960050759133]\n",
        "\n",
        "# Colors for each model\n",
        "colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc']\n",
        "\n",
        "# Create pie plots for each experiment\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
        "fig.suptitle('Optimal Ensemble Weights for Each Experiment', fontsize=16)\n",
        "\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "    labels = []\n",
        "    sizes = []\n",
        "    for key, value in weights[i].items():\n",
        "        if value > 0:\n",
        "            labels.append(key)\n",
        "            sizes.append(value)\n",
        "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "    ax.set_title(f'Experiment: {experiments[i]}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('ensemble_weights_pie_charts.png')\n",
        "plt.close()\n",
        "\n",
        "# Create average distribution pie chart\n",
        "avg_weights = {key: np.mean([w[key] for w in weights]) for key in weights[0]}\n",
        "labels = []\n",
        "sizes = []\n",
        "for key, value in avg_weights.items():\n",
        "    if value > 0:\n",
        "        labels.append(key)\n",
        "        sizes.append(value)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "plt.title('Average Distribution of Optimal Ensemble Weights', fontsize=16)\n",
        "plt.savefig('average_ensemble_weights_pie_chart.png')\n",
        "plt.close()\n",
        "\n",
        "# Create bar plot comparing R2 scores\n",
        "x = np.arange(len(experiments))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "rects1 = ax.bar(x - width/2, ensemble_r2, width, label='Optimal Ensemble', color='#66b3ff')\n",
        "rects2 = ax.bar(x + width/2, autogluon_r2, width, label='AutoGluon (225 sec)', color='#ff9999')\n",
        "\n",
        "ax.set_ylabel('R2 Score')\n",
        "ax.set_title('Comparison of R2 Scores: Optimal Ensemble vs AutoGluon', fontsize=16)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(experiments)\n",
        "ax.legend()\n",
        "\n",
        "ax.bar_label(rects1, padding=3, fmt='%.4f')\n",
        "ax.bar_label(rects2, padding=3, fmt='%.4f')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.savefig('r2_score_comparison.png')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87651bc-c99b-4a27-9feb-2edb391dcfe8",
      "metadata": {
        "id": "e87651bc-c99b-4a27-9feb-2edb391dcfe8",
        "jupyter": {
          "source_hidden": true
        },
        "outputId": "54d1b630-3807-476d-b8e5-a55f41c4676a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 14 (exam set), split train/test: 0.2, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.9018991352967078\n",
            "flaml r2: 0.9021714011999556\n",
            "gluon r2: 0.9082444600501948\n",
            "tpot r2: 0.85345478487002\n",
            "mljar r2: 0.9066244754568729\n",
            "Initial weights: FLAML: 0.202, AutoSklearn: 0.202, Gluon: 0.203, TPOT: 0.2031, MLJAR: 0.20308\n",
            "Optimal weights: FLAML: 0.000, AutoSklearn: 0.067, Gluon: 0.584, TPOT: 0.0000, MLJAR: 0.34891\n",
            "Optimal ensemble R2: 0.908760\n",
            "\n",
            "Compared with a 225 sec autogluon run on same dataset. 0.9090960050759133\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 14 (exam set), split train/test: 0.2, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 225 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c889078-5f27-448d-a565-74e5962c03f9",
      "metadata": {
        "id": "8c889078-5f27-448d-a565-74e5962c03f9",
        "outputId": "cf927fe4-33be-4b79-935a-c7af5b0aeb5b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 13 - property, pre split train/test, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.025615876031262363\n",
            "flaml r2: 0.9292393814353446\n",
            "gluon r2: 0.8970115852805034\n",
            "tpot r2: 0.3901742233619726\n",
            "mljar r2: 0.9038038161802924\n",
            "Initial weights: FLAML: 0.295, AutoSklearn: 0.008, Gluon: 0.285, TPOT: 0.2851, MLJAR: 0.28514\n",
            "Optimal weights: FLAML: 0.790, AutoSklearn: 0.000, Gluon: 0.066, TPOT: 0.0000, MLJAR: 0.14347\n",
            "Optimal ensemble R2: 0.929676\n",
            "\n",
            "Compared with a 225 sec autogluon run on same dataset. 0.8973623343877719\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 13 - property, pre split train/test, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 225 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1021d60a-dd49-47ca-915c-4dfc739ab479",
      "metadata": {
        "id": "1021d60a-dd49-47ca-915c-4dfc739ab479",
        "outputId": "c6fb1fe1-2ffa-4d1f-e2d5-e3b407aaad03",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 12 - Brazil, pre split train/test, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.9987812976782319\n",
            "flaml r2: 0.9998829775590306\n",
            "gluon r2: 0.9999361241713965\n",
            "tpot r2: 0.994005936813352\n",
            "mljar r2: 0.9998062947255467\n",
            "Initial weights: FLAML: 0.200, AutoSklearn: 0.200, Gluon: 0.200, TPOT: 0.2003, MLJAR: 0.20029\n",
            "Optimal weights: FLAML: 0.273, AutoSklearn: 0.000, Gluon: 0.544, TPOT: 0.0000, MLJAR: 0.18274\n",
            "Optimal ensemble R2: 0.999959\n",
            "\n",
            "Compared with a 225 sec autogluon run on same dataset. 0.9999610596082303\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 12 - Brazil, pre split train/test, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 225 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3899d29f-89c7-4024-a121-e9f3f2a09baa",
      "metadata": {
        "id": "3899d29f-89c7-4024-a121-e9f3f2a09baa",
        "outputId": "fe89948b-13fd-44ea-acf0-07a9dd975ba7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 11 - bike set, pre split train/test, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.96424752975455\n",
            "flaml r2: 0.9812247807406366\n",
            "gluon r2: 0.9801217428409494\n",
            "tpot r2: 0.9385249767051255\n",
            "mljar r2: 0.9795437216375422\n",
            "Initial weights: FLAML: 0.203, AutoSklearn: 0.199, Gluon: 0.202, TPOT: 0.2024, MLJAR: 0.20235\n",
            "Optimal weights: FLAML: 0.495, AutoSklearn: 0.000, Gluon: 0.238, TPOT: 0.0000, MLJAR: 0.26731\n",
            "Optimal ensemble R2: 0.983029\n",
            "\n",
            "Compared with a 225 sec autogluon run on same dataset. 0.980324167040719\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 11 - bike set, pre split train/test, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 225 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ee0c86-a5ed-483a-a1c6-967a1325872f",
      "metadata": {
        "id": "87ee0c86-a5ed-483a-a1c6-967a1325872f",
        "outputId": "10895ae6-3c47-4033-ed13-3e8803e42f42",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 10 (exam set), split train/test: 0.2, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.9464678404550451\n",
            "flaml r2: 0.92094008726315\n",
            "gluon r2: 0.9477057918725242\n",
            "tpot r2: 0.8802628203042405\n",
            "mljar r2: 0.9429443640791044\n",
            "Initial weights: FLAML: 0.199, AutoSklearn: 0.204, Gluon: 0.204, TPOT: 0.2043, MLJAR: 0.20432\n",
            "Optimal weights: FLAML: 0.000, AutoSklearn: 0.443, Gluon: 0.557, TPOT: 0.0000, MLJAR: 0.00000\n",
            "Optimal ensemble R2: 0.949917\n",
            "\n",
            "Compared with a 225 sec autogluon run on same dataset. 0.9466974619226166\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 10 (exam set), split train/test: 0.2, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', autosklearn_score)\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "print('mljar r2:', mljar_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}, MLJAR: {initial_weights[2]:.5f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}, MLJAR: {w5:.5f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 225 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5efaba0-0bae-41ec-be51-89ef561d9ed7",
      "metadata": {
        "id": "c5efaba0-0bae-41ec-be51-89ef561d9ed7"
      },
      "outputs": [],
      "source": [
        "print(f'Experiment 9, {base_path}, pre split train/test, train subsample = 20 000, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', r2_score(test[label], autosklearn_pred))\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, \"\n",
        "      f\"Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[3]:.3f}, MLJAR: {initial_weights[4]:.3f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.3f}, MLJAR: {w5:.3f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 195 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e3c1b1-4394-4eba-8121-7203e682aecd",
      "metadata": {
        "collapsed": true,
        "id": "63e3c1b1-4394-4eba-8121-7203e682aecd",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8922ee25-593c-4091-b33e-2340f441b3a6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 8 (exam set), split train/test: 0.2, random_seed=100, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.943178769284982\n",
            "flaml r2: 0.9157893012151598\n",
            "gluon r2: 0.9430203638395451\n",
            "tpot r2: 0.8530380803372511\n",
            "Initial weights: FLAML: 0.251, AutoSklearn: 0.258, Gluon: 0.258, TPOT: 0.2580\n",
            "Optimal weights: FLAML: 0.000, AutoSklearn: 0.345, Gluon: 0.337, TPOT: 0.0000\n",
            "Optimal ensemble R2: 0.945840\n",
            "\n",
            "Compared with a 195 sec autogluon run on same dataset. 0.9430960612867438\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 8 (exam set), split train/test: 0.2, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', r2_score(test[label], autosklearn_pred))\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2:', tpot_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 195 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a175ad-dce8-4348-bdf0-cae4e9722f78",
      "metadata": {
        "collapsed": true,
        "id": "d8a175ad-dce8-4348-bdf0-cae4e9722f78",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "930d7bc0-1162-4483-c5cc-7f01199b30d2",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 7, ../../data/361098, pre split train/test, train subsample = 20 000, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: -2.0545698919960387e-08\n",
            "flaml r2: 0.9997542121304047\n",
            "gluon r2: 0.9999007470404888\n",
            "tpot r2 (60 sec): 0.9966102873818953\n",
            "Initial weights: FLAML: 0.334, AutoSklearn: 0.000, Gluon: 0.334, TPOT: 0.3337\n",
            "Optimal weights: FLAML: 0.634, AutoSklearn: 0.000, Gluon: 0.564, TPOT: 0.0326         # using skopt.gp_minimize\n",
            "Optimal ensemble R2: 0.999894\n",
            "\n",
            "Compared with a 180 sec autogluon run on same dataset. 0.9999499985304586\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 7, {base_path}, pre split train/test, train subsample = 20 000, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', r2_score(test[label], autosklearn_pred))\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "print('tpot r2 (60 sec):', tpot_score)\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}, TPOT: {initial_weights[2]:.4f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}, TPOT: {w4:.4f}         # using skopt.gp_minimize\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 180 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1984d11-e4eb-4247-b122-5538c04d12f5",
      "metadata": {
        "collapsed": true,
        "id": "b1984d11-e4eb-4247-b122-5538c04d12f5",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "c3a8c7c1-cc31-48e1-e756-839219a1e668",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 6, ../../data/361098, pre split train/test, train subsample = 20 000, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: -2.0545698919960387e-08\n",
            "flaml r2: 0.9997542121304047\n",
            "gluon r2: 0.9999007470404888\n",
            "R2 score 33/33/33 FLAML, gluon, autosklearn 0.7494935506893418\n",
            "R2 score ensemble 50/50 FLAML and gluon 0.9999030672087769\n",
            "Initial weights: FLAML: 0.500, AutoSklearn: 0.000, Gluon: 0.500\n",
            "Optimal weights: FLAML: 0.200, AutoSklearn: 0.000, Gluon: 0.711          # using skopt.gp_minimize\n",
            "Optimal ensemble R2: 0.999920\n",
            "\n",
            "Compared with a 135 sec autogluon run on same dataset. 0.9999479563293344\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 6, {base_path}, pre split train/test, train subsample = 20 000, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', r2_score(test[label], autosklearn_pred))\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "ensemble_4 = (flaml_pred + autosklearn_pred + gluon_pred) / 3\n",
        "print('R2 score 33/33/33 FLAML, gluon, autosklearn', r2_score(ensemble_4, test[label]))\n",
        "ensemble_3 = (gluon_pred + flaml_pred) / 2\n",
        "print('R2 score ensemble 50/50 FLAML and gluon', r2_score(ensemble_3, test[label]))\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}          # using skopt.gp_minimize\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 135 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d00d0ea-d4cf-4dee-9bce-56c134166db9",
      "metadata": {
        "collapsed": true,
        "id": "9d00d0ea-d4cf-4dee-9bce-56c134166db9",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "501a8c83-52b5-4595-a559-447d0c4480e3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 5, ../../data/361099, pre split train/test, train subsample = 20 000, random_seed=42, 45 sec each \n",
            "\n",
            "\n",
            "autosklearn r2: 0.96424752975455\n",
            "flaml r2: 0.9793072031648467\n",
            "gluon r2: 0.9775395392560148\n",
            "R2 score 33/33/33 FLAML, gluon, autosklearn 0.9777513822896438\n",
            "R2 score ensemble 50/50 FLAML and gluon 0.9806118558444856\n",
            "Initial weights: FLAML: 0.335, AutoSklearn: 0.330, Gluon: 0.335\n",
            "Optimal weights: FLAML: 0.635, AutoSklearn: 0.030, Gluon: 0.447          # using skopt.gp_minimize\n",
            "Optimal ensemble R2: 0.981362\n",
            "\n",
            "Compared with a 135 sec autogluon run on same dataset. 0.9801217428409494\n"
          ]
        }
      ],
      "source": [
        "print(f'Experiment 5, {base_path}, pre split train/test, train subsample = 20 000, random_seed={random_seed}, {time} sec each \\n\\n')\n",
        "\n",
        "print('autosklearn r2:', r2_score(test[label], autosklearn_pred))\n",
        "print('flaml r2:', flaml_score)\n",
        "print('gluon r2:', eval_gluon['r2'])\n",
        "ensemble_4 = (flaml_pred + autosklearn_pred + gluon_pred) / 3\n",
        "print('R2 score 33/33/33 FLAML, gluon, autosklearn', r2_score(ensemble_4, test[label]))\n",
        "ensemble_3 = (gluon_pred + flaml_pred) / 2\n",
        "print('R2 score ensemble 50/50 FLAML and gluon', r2_score(ensemble_3, test[label]))\n",
        "\n",
        "print(f\"Initial weights: FLAML: {initial_weights[0]:.3f}, AutoSklearn: {initial_weights[1]:.3f}, Gluon: {initial_weights[2]:.3f}\")\n",
        "print(f\"Optimal weights: FLAML: {w1:.3f}, AutoSklearn: {w2:.3f}, Gluon: {w3:.3f}          # using skopt.gp_minimize\")\n",
        "print(f\"Optimal ensemble R2: {optimal_r2:.6f}\")\n",
        "\n",
        "print('\\nCompared with a 135 sec autogluon run on same dataset.', eval_benchmark['r2'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sagemaker-distribution:Python",
      "language": "python",
      "name": "conda-env-sagemaker-distribution-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
